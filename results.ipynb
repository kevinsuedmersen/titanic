{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attractive-professor",
   "metadata": {},
   "source": [
    "# Titanic ML Competition\n",
    "Goal: Predict whether a passenger survives or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "overall-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-16 18:11:22,916; src.utils; INFO; Root logger is set up\n"
     ]
    }
   ],
   "source": [
    "from src.pipeline import MLPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-chapel",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "- What kind of columns does the dataset have? Which one are numeric, which one are categorical?\n",
    "- Are there missing values?\n",
    "- Are there duplicates?\n",
    "- How is the ground truth distributed? ==> Important for evaluation metric choice. If unequally distributed, accuracy might be misleading and precision/recall/f1 might be better\n",
    "- \"Datenverst√§ndnis\" gewinnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "retired-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-16 18:11:22,933; src.preprocessing; INFO; Train samples: \"891\"\n",
      "2021-02-16 18:11:22,940; src.preprocessing; INFO; Test samples: \"418\"\n",
      "2021-02-16 18:11:22,958; src.preprocessing; INFO; Total samples: \"1309\"\n",
      "2021-02-16 18:11:22,960; src.preprocessing; INFO; Joined train and test sets together for the preprocessing. For training and testing, they will be separated again\n",
      "2021-02-16 18:11:22,961; src.preprocessing; INFO; A profiling report was already generated and is located at ``results/ds_profile_report.html``\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1000\"\n",
       "            src=\"results/ds_profile_report.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f63ac86beb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup\n",
    "MISSING_VALUE_CONFIG = {\n",
    "    'Age': 'median', \n",
    "    'Embarked': 'mode',\n",
    "    'Fare': 'median'\n",
    "}\n",
    "ENCODING_CONFIG = {\n",
    "    'Pclass': {1: 3, 2: 2, 3: 1}, # original_value: encoding_value\n",
    "    'Sex': {'male': 1, 'female': 0},\n",
    "    'Embarked': 'one_hot'\n",
    "}\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'svm': {'kernel': 'rbf'},\n",
    "    'decision_tree': {},\n",
    "    'random_forest': {}\n",
    "}\n",
    "ml_pipeline = MLPipeline(\n",
    "    df_path_train='data/train.csv', \n",
    "    df_path_test='data/test.csv', \n",
    "    id_col='PassengerId', \n",
    "    ground_truth='Survived', \n",
    "    missing_value_config=MISSING_VALUE_CONFIG, \n",
    "    encoding_config=ENCODING_CONFIG, \n",
    "    model_config=MODEL_CONFIG\n",
    ")\n",
    "\n",
    "ml_pipeline.run_eda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-render",
   "metadata": {},
   "source": [
    "- Ground truth (Survived) not very equally distributed ==> Also use precision, recall and f1 when evaluating the model. Should hyper-parameter tuning be performed, the best model will be chosen based on accuracy though, because this is the main evaluation metric used in the kaggle competition\n",
    "- Survival might depend on socio-economic status which might be inherent in the person's name or title. ==> Try to split up the name column in `first_name`, `middle_name`, `last_name`, `title`\n",
    "- Lots of missing values in `Age` and distribution looks skewed with some outliers. ==> Fill with median, because in skewed distributions, the median might be better representation of a \"common\" value \n",
    "- Survival might depend on gender, because woman and children were supposed to board the emergency boats first\n",
    "- Extract some more information from `Ticket`, such as sections, floors, etc. Passengers from lower decks might have lower survival chances, because lower decks could have been flooded first\n",
    "- 0.2% Missing values of `Fare` in the test dataset ==> Fill with median, because its distribution is highly skewed \n",
    "- more than 75% missing values in `Cabin` ==> Either ignore that column completely, or fill with mode\n",
    "- Few missing values in `Embarked`. ==> Fill with mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-berry",
   "metadata": {},
   "source": [
    "## Iteration 1\n",
    "- Fill `Age` with median\n",
    "- Fill `Embarked` with mode\n",
    "- Label-encode `Pclass` such that class 1 (for the rich and famous people) has the highest value and class 3 (for working class people) has the lowest value\n",
    "- One-hot encode the following categorical variables: `Sex, Embarked`\n",
    "- Only use the following predictors: `Pclass, Sex, Age, SibSp, Parch, Fare, Embarked`\n",
    "- Use SVM with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "healthy-signal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-16 18:11:23,007; src.preprocessing; INFO; The median of column ``Age`` equals: 28.0\n",
      "2021-02-16 18:11:23,013; src.preprocessing; INFO; The mode of column ``Embarked`` equals: S\n",
      "2021-02-16 18:11:23,020; src.preprocessing; INFO; The median of column ``Fare`` equals: 14.4542\n",
      "2021-02-16 18:11:23,032; src.preprocessing; INFO; Converted column ``Pclass`` using the custom mapping ``{1: 3, 2: 2, 3: 1}``\n",
      "2021-02-16 18:11:23,041; src.preprocessing; INFO; Converted column ``Sex`` using the custom mapping ``{'male': 1, 'female': 0}``\n",
      "2021-02-16 18:11:23,061; src.preprocessing; INFO; One-hot encoded the column ``Embarked``\n",
      "2021-02-16 18:11:23,062; src.preprocessing; INFO; Preprocessing finished\n",
      "2021-02-16 18:11:23,068; src.preprocessing; INFO; Available columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  \\\n",
       "0              1       0.0       1    1  22.0      1      0   7.2500   \n",
       "1              2       1.0       3    0  38.0      1      0  71.2833   \n",
       "2              3       1.0       1    0  26.0      0      0   7.9250   \n",
       "3              4       1.0       3    0  35.0      1      0  53.1000   \n",
       "4              5       0.0       1    1  35.0      0      0   8.0500   \n",
       "..           ...       ...     ...  ...   ...    ...    ...      ...   \n",
       "886          887       0.0       2    1  27.0      0      0  13.0000   \n",
       "887          888       1.0       3    0  19.0      0      0  30.0000   \n",
       "888          889       0.0       1    0  28.0      1      2  23.4500   \n",
       "889          890       1.0       3    1  26.0      0      0  30.0000   \n",
       "890          891       0.0       1    1  32.0      0      0   7.7500   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  \n",
       "0             0           0           1  \n",
       "1             1           0           0  \n",
       "2             0           0           1  \n",
       "3             0           0           1  \n",
       "4             0           0           1  \n",
       "..          ...         ...         ...  \n",
       "886           0           0           1  \n",
       "887           0           0           1  \n",
       "888           0           0           1  \n",
       "889           1           0           0  \n",
       "890           0           1           0  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-16 18:11:23,125; src.training; INFO; Training ``svm`` started\n",
      "2021-02-16 18:11:23,129; src.training; INFO; Saved the trained model to ``results/min_max_scaler.pickle``\n",
      "2021-02-16 18:11:23,148; src.training; INFO; Training finished\n",
      "2021-02-16 18:11:23,158; src.training; INFO; Results on the validation set: accuracy 0.80, precision 0.86, recall 0.61, f1 0.72\n",
      "2021-02-16 18:11:23,159; src.training; INFO; Saved the trained model to ``results/svm_model.pickle``\n",
      "2021-02-16 18:11:23,164; src.training; INFO; Saved the trained model to ``results/min_max_scaler.pickle``\n",
      "2021-02-16 18:11:23,166; src.training; INFO; Generating predictions on the test set\n",
      "2021-02-16 18:11:23,177; src.training; INFO; Saved submission to ``results/basic_preprocessing_submission.csv``\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "col_name_to_fill_method = {\n",
    "    'Age': 'median', \n",
    "    'Embarked': 'mode',\n",
    "    'Fare': 'median'\n",
    "}\n",
    "col_name_to_encoding = {\n",
    "    'Pclass': {1: 3, 2: 2, 3: 1}, # original_value: encoding_value\n",
    "    'Sex': {'male': 1, 'female': 0},\n",
    "    'Embarked': 'one_hot'\n",
    "}\n",
    "\n",
    "# Preprocessing\n",
    "ds.do_basic_preprocessing(col_name_to_fill_method, col_name_to_encoding)\n",
    "cols_to_drop = ['Name', 'Ticket', 'Cabin', 'Embarked']\n",
    "train_df = ds.select(cols_to_drop, mode='training')\n",
    "display(train_df)\n",
    "test_df = ds.select(cols_to_drop, mode='testing')\n",
    "\n",
    "# Training, predicting and evaluating\n",
    "model = Model(\n",
    "    model_name='svm',\n",
    "    model_path='results/svm_model.pickle', \n",
    "    ground_truth='Survived', \n",
    "    id_col_name='PassengerId',\n",
    "    scaling_mode='min_max',\n",
    "    scaler_path='results/min_max_scaler.pickle',\n",
    "    kernel='rbf'\n",
    ")\n",
    "model.train_and_evaluate(train_df)\n",
    "model.gen_submission_file(test_df, submission_path='results/basic_preprocessing_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-alexandria",
   "metadata": {},
   "source": [
    "### Results iteration 1\n",
    "- Results on the validation set: accuracy 0.80, precision 0.86, recall 0.61, f1 0.72\n",
    "- After uploading our submission file `results/basic_prepreprocessing_submission.csv` to kaggle, the result on the test set was an accuracy score of `0.77751`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-logan",
   "metadata": {},
   "source": [
    "## Iteration 2\n",
    "- Build upon iteration 1\n",
    "- Use feature engineering ideas from https://www.kaggle.com/imoore/titanic-the-only-notebook-you-need-to-see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extended-kernel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-16 18:11:23,223; src.preprocessing; INFO; Available columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'name_len', 'family_size', 'has_cabin', 'is_alone', 'fare_category', 'age_category', 'title', 'title_capt', 'title_col', 'title_countess', 'title_don', 'title_dona', 'title_dr', 'title_jonkheer', 'title_lady', 'title_major', 'title_master', 'title_miss', 'title_mlle', 'title_mme', 'title_mr', 'title_mrs', 'title_ms', 'title_rev', 'title_sir']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>...</th>\n",
       "      <th>title_major</th>\n",
       "      <th>title_master</th>\n",
       "      <th>title_miss</th>\n",
       "      <th>title_mlle</th>\n",
       "      <th>title_mme</th>\n",
       "      <th>title_mr</th>\n",
       "      <th>title_mrs</th>\n",
       "      <th>title_ms</th>\n",
       "      <th>title_rev</th>\n",
       "      <th>title_sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  \\\n",
       "0              1       0.0       1    1  22.0      1      0   7.2500   \n",
       "1              2       1.0       3    0  38.0      1      0  71.2833   \n",
       "2              3       1.0       1    0  26.0      0      0   7.9250   \n",
       "3              4       1.0       3    0  35.0      1      0  53.1000   \n",
       "4              5       0.0       1    1  35.0      0      0   8.0500   \n",
       "..           ...       ...     ...  ...   ...    ...    ...      ...   \n",
       "886          887       0.0       2    1  27.0      0      0  13.0000   \n",
       "887          888       1.0       3    0  19.0      0      0  30.0000   \n",
       "888          889       0.0       1    0  28.0      1      2  23.4500   \n",
       "889          890       1.0       3    1  26.0      0      0  30.0000   \n",
       "890          891       0.0       1    1  32.0      0      0   7.7500   \n",
       "\n",
       "     Embarked_C  Embarked_Q  ...  title_major  title_master  title_miss  \\\n",
       "0             0           0  ...            0             0           0   \n",
       "1             1           0  ...            0             0           0   \n",
       "2             0           0  ...            0             0           1   \n",
       "3             0           0  ...            0             0           0   \n",
       "4             0           0  ...            0             0           0   \n",
       "..          ...         ...  ...          ...           ...         ...   \n",
       "886           0           0  ...            0             0           0   \n",
       "887           0           0  ...            0             0           1   \n",
       "888           0           0  ...            0             0           1   \n",
       "889           1           0  ...            0             0           0   \n",
       "890           0           1  ...            0             0           0   \n",
       "\n",
       "     title_mlle  title_mme  title_mr  title_mrs  title_ms  title_rev  \\\n",
       "0             0          0         1          0         0          0   \n",
       "1             0          0         0          1         0          0   \n",
       "2             0          0         0          0         0          0   \n",
       "3             0          0         0          1         0          0   \n",
       "4             0          0         1          0         0          0   \n",
       "..          ...        ...       ...        ...       ...        ...   \n",
       "886           0          0         0          0         0          1   \n",
       "887           0          0         0          0         0          0   \n",
       "888           0          0         0          0         0          0   \n",
       "889           0          0         1          0         0          0   \n",
       "890           0          0         1          0         0          0   \n",
       "\n",
       "     title_sir  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "886          0  \n",
       "887          0  \n",
       "888          0  \n",
       "889          0  \n",
       "890          0  \n",
       "\n",
       "[891 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-16 18:11:23,278; src.training; INFO; Training ``svm`` started\n",
      "2021-02-16 18:11:23,286; src.training; INFO; Saved the trained model to ``results/min_max_scaler.pickle``\n",
      "2021-02-16 18:11:23,308; src.training; INFO; Training finished\n",
      "2021-02-16 18:11:23,318; src.training; INFO; Results on the validation set: accuracy 0.82, precision 0.85, recall 0.68, f1 0.76\n",
      "2021-02-16 18:11:23,320; src.training; INFO; Saved the trained model to ``results/svm_model.pickle``\n",
      "2021-02-16 18:11:23,324; src.training; INFO; Saved the trained model to ``results/min_max_scaler.pickle``\n",
      "2021-02-16 18:11:23,325; src.training; INFO; Generating predictions on the test set\n",
      "2021-02-16 18:11:23,339; src.training; INFO; Saved submission to ``results/advanced_preprocessing_submission.csv``\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "ds.do_advanced_preprocessing()\n",
    "cols_to_drop += ['title']\n",
    "train_df = ds.select(cols_to_drop, mode='training')\n",
    "display(train_df)\n",
    "test_df = ds.select(cols_to_drop, mode='testing')\n",
    "\n",
    "# Training, predicting and evaluating\n",
    "model = Model(\n",
    "    model_name='svm',\n",
    "    model_path='results/svm_model.pickle', \n",
    "    ground_truth='Survived', \n",
    "    id_col_name='PassengerId',\n",
    "    scaling_mode='min_max',\n",
    "    scaler_path='results/min_max_scaler.pickle',\n",
    "    kernel='rbf'\n",
    ")\n",
    "model.train_and_evaluate(train_df)\n",
    "model.gen_submission_file(test_df, submission_path='results/advanced_preprocessing_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-advance",
   "metadata": {},
   "source": [
    "### Results iteration 2\n",
    "- Results on the validation set: accuracy 0.82, precision 0.85, recall 0.68, f1 0.76\n",
    "- After uploaded the `results/advanced_preprocessing_submission.csv` file to kaggle, the accuracy on the test set was `0.77751`\n",
    "- While the results on the validation set slightly improved, astonishingly, the test set score remained exactly the same. I made sure that `results/basic_preprocessing_submission.csv` and `results/advanced_preprocessing_submission.csv` actually contain different values, so this mus have happened by chance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-nicholas",
   "metadata": {},
   "source": [
    "## Iteration 3\n",
    "- Build upon iteration 2\n",
    "- Use hyper-parameter tuning to find optimal values for `C, gamma`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-bookmark",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "- Explain used model\n",
    "- Extract numbers and letters from the `Ticket` column\n",
    "- Use Decision Tree Model\n",
    "- Use Random Forest Model\n",
    "- Simple meta modelling\n",
    "- Precision recall Plot\n",
    "- Confusion matrix\n",
    "- Update docstrings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
